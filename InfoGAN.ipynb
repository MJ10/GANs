{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plot\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "X_dim = 784\n",
    "z_dim = 16\n",
    "c_dim = 10\n",
    "h_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_images(samples):\n",
    "    fig = plot.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plot.subplot(gs[i])\n",
    "        plot.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plot.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xavier_init(size):\n",
    "    input_dim = size[0]\n",
    "    xavier_stddev = 1. / tf.sqrt(input_dim / 2.)\n",
    "    return tf.random_normal(shape=size, stddev=xavier_stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, X_dim])\n",
    "\n",
    "D_W1 = tf.Variable(xavier_init([X_dim, h_dim]))\n",
    "D_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
    "\n",
    "D_W2 = tf.Variable(xavier_init([h_dim, 1]))\n",
    "D_b2 = tf.Variable(tf.zeros(shape=[1]))\n",
    "\n",
    "theta_D = [D_W1, D_W2, D_b1, D_b2]\n",
    "\n",
    "\n",
    "z = tf.placeholder(tf.float32, shape=[None, z_dim])\n",
    "c = tf.placeholder(tf.float32, shape=[None, c_dim])\n",
    "\n",
    "G_W1 = tf.Variable(xavier_init([z_dim + c_dim, h_dim // 2]))\n",
    "G_b1 = tf.Variable(tf.zeros(shape=[h_dim // 2]))\n",
    "\n",
    "G_W2 = tf.Variable(xavier_init([h_dim // 2, X_dim]))\n",
    "G_b2 = tf.Variable(tf.zeros(shape=[X_dim]))\n",
    "\n",
    "theta_G = [G_W1, G_W2, G_b1, G_b2]\n",
    "\n",
    "Q_W1 = tf.Variable(xavier_init([X_dim, h_dim // 2]))\n",
    "Q_b1 = tf.Variable(tf.zeros(shape=[h_dim // 2]))\n",
    "\n",
    "Q_W2 = tf.Variable(xavier_init([h_dim // 2, 10]))\n",
    "Q_b2 = tf.Variable(tf.zeros(shape=[10]))\n",
    "\n",
    "theta_Q = [Q_W1, Q_W2, Q_b1, Q_b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sample_z(size):\n",
    "    return np.random.uniform(-1., 1., size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sample_c(m):\n",
    "    return np.random.multinomial(1, 10*[0.1], size=m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z, c):\n",
    "    inputs = tf.concat(axis=1, values=[z, c])\n",
    "    G_h1 = tf.nn.relu(tf.matmul(inputs, G_W1) + G_b1)\n",
    "    G_out = tf.sigmoid(tf.matmul(G_h1, G_W2) + G_b2)\n",
    "    return G_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(x):\n",
    "    D_h1 = tf.nn.relu(tf.matmul(x, D_W1) + D_b1)\n",
    "    D_out = tf.matmul(D_h1, D_W2) + D_b2\n",
    "    return D_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Q(x):\n",
    "    Q_h1 = tf.nn.relu(tf.matmul(x, Q_W1) + Q_b1)\n",
    "    Q_out = tf.nn.softmax(tf.matmul(Q_h1, Q_W2) + Q_b2)\n",
    "    return Q_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_sample = generator(z, c)\n",
    "discriminator_real = discriminator(X)\n",
    "discriminator_fake = discriminator(generator_sample)\n",
    "q_c_x = Q(generator_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_loss = -tf.reduce_mean(tf.log(discriminator_real + 1e-8) + tf.log(1 - discriminator_fake + 1e-8))\n",
    "g_loss = -tf.reduce_mean(tf.log(discriminator_fake + 1e-8))\n",
    "q_loss = tf.reduce_mean(-tf.reduce_sum(tf.log(q_c_x + 1e-8) * c, 1)) + \\\n",
    "            tf.reduce_mean(-tf.reduce_sum(tf.log(c + 1e-8) * c, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_step = tf.train.AdamOptimizer(0.0001).minimize(d_loss, var_list=theta_D)\n",
    "g_step = tf.train.AdamOptimizer(0.0001).minimize(g_loss, var_list=theta_G)\n",
    "q_step = tf.train.AdamOptimizer(0.0001).minimize(q_loss, var_list=theta_G + theta_Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100000):\n",
    "    x_batch, _ = mnist.train.next_batch(batch_size)\n",
    "    z_batch = get_sample_z((batch_size, z_dim))\n",
    "    c_batch = get_sample_c(batch_size)\n",
    "    \n",
    "    _, d_loss_val = sess.run(\n",
    "        [d_step, d_loss],\n",
    "        feed_dict={X: x_batch, z: z_batch, c: c_batch}\n",
    "    )\n",
    "\n",
    "    _, g_loss_val = sess.run(\n",
    "        [g_step, g_loss],\n",
    "        feed_dict={z: z_batch, c: c_batch}\n",
    "    )\n",
    "    \n",
    "    sess.run([q_step], feed_dict={z: z_batch, c: c_batch})\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print('Iteration: {} - Discriminator Loss: {:.4}, Generator Loss: {:.4}'\n",
    "              .format(i, d_loss_val, g_loss_val))\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            samples = sess.run(generator_sample, feed_dict={z: get_sample_z(size=(16, z_dim)),\n",
    "                                                            c: get_sample_c(16)})\n",
    "\n",
    "            fig = plot_images(samples)\n",
    "            plot.show()\n",
    "            plot.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
